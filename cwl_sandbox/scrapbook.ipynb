{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapbook\n",
    "\n",
    "This is a deconstruction of the initial setup for our emcee gp optimizer. \n",
    "\n",
    "Let's start by importing all the functions and packages we might need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook \n",
    "#restart the kernel if switching from inline to notebook\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-white')\n",
    "import corner\n",
    "\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import pandas as pd\n",
    "\n",
    "import emcee\n",
    "import george\n",
    "\n",
    "import gp_sandbox as cgp\n",
    "from subsample import subsample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can get our asteroid time and data info from our text files. We will then be able to sample it using Daniela's subsample method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "asteroid = 1388\n",
    "txt = '../data/'+str(asteroid)+'_lc_49627_to_49787.txt'\n",
    "\n",
    "data = pd.read_csv(txt, delimiter=' ',\n",
    "                 header=None, names=['time','flux'], dtype={'time':float, 'flux':float})\n",
    "\n",
    "days, delay = 5, 2\n",
    "\n",
    "# convert days to points\n",
    "span = 2880 * days\n",
    "start_pt = 2880 * delay\n",
    "\n",
    "time = np.array(data.time[start_pt:span+start_pt])\n",
    "flux = np.array(data.flux[start_pt:span+start_pt])\n",
    "\n",
    "f_err = np.ones_like(flux) * np.std(flux)/10.0\n",
    "\n",
    "tsample, fsample, flux_err = subsample(time, flux, flux_err=f_err, npoints=100, kind=\"random\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check and make sure the flux amplitude looks reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010171214528505116"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_log_amp = np.log(fsample.var())\n",
    "np.exp(best_log_amp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can set up what we think our parameter values might be. We can use the log_amp if it seems reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, -4.5881936533867842, 1, -1.38]\n"
     ]
    }
   ],
   "source": [
    "params = [1, best_log_amp, 1, -1.38]\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('mean:value', 'white_noise:value', 'kernel:k1:log_constant', 'kernel:k2:gamma', 'kernel:k2:log_period')\n",
      "[  0.         -27.40787756  -4.58819365   1.          -1.38      ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('kernel:k1:log_constant', -4.5881936533867842),\n",
       "             ('kernel:k2:gamma', 1.0),\n",
       "             ('kernel:k2:log_period', -1.3799999999999999)])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean, log_amp, gamma, log_period = params\n",
    "\n",
    "amp = np.exp(log_amp)\n",
    "kernel = amp * george.kernels.ExpSine2Kernel(gamma = gamma, log_period = log_period)\n",
    "gp = george.GP(kernel)#, fit_mean=True, mean=mean)\n",
    "gp.compute(tsample, flux_err)\n",
    "print(gp.parameter_names)\n",
    "print(gp.parameter_vector)\n",
    "\n",
    "\n",
    "gp.get_parameter_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('kernel:k1:log_constant', -4.5881936533867842),\n",
       "             ('kernel:k2:gamma', 1.0),\n",
       "             ('kernel:k2:log_period', -1.3799999999999999)])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute kernel with given time and error\n",
    "gp.compute(tsample, flux_err)\n",
    "gp.get_parameter_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.58819365,  1.        , -1.38      ])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0 = gp.get_parameter_vector()\n",
    "type(x0)\n",
    "x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnds = ([-10.,30.],[0.,100.],[-3.178,0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.88868296e+05  -1.06690561e+05  -3.59463180e+02]\n",
      " [ -1.06690561e+05   3.94051114e+04   1.32764222e+02]\n",
      " [ -3.59463180e+02   1.32764222e+02   4.47311297e-01]]\n",
      "[-1.01439405  0.545576   -1.38948455]\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def neg_ln_like(p):\n",
    "    gp.set_parameter_vector(p)\n",
    "    try:\n",
    "        negloglike =  -gp.log_likelihood(fsample)\n",
    "        return negloglike\n",
    "    # throw exception if you run into an error\n",
    "    except scipy.linalg.LinAlgError:\n",
    "        return np.inf\n",
    "\n",
    "def grad_neg_ln_like(p):\n",
    "    gp.set_parameter_vector(p)\n",
    "    try:\n",
    "        grad_loglike =  -gp.grad_log_likelihood(fsample)\n",
    "        return grad_loglike\n",
    "    # throw exception if you run into an error\n",
    "    except scipy.linalg.LinAlgError:\n",
    "        return np.inf\n",
    "\n",
    "result = minimize(fun=neg_ln_like, x0=x0, method='L-BFGS-B', jac=grad_neg_ln_like)#, bounds=bnds)\n",
    "print(result.hess_inv.todense())\n",
    "print(result.x)\n",
    "#gp.set_parameter_vector(result.x)\n",
    "\n",
    "#if (print_result == True):\n",
    "#    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp.set_parameter_vector(result.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cov must be 2 dimensional and square",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-2d0f3d340d87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mp0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultivariate_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhess_inv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.multivariate_normal\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cov must be 2 dimensional and square"
     ]
    }
   ],
   "source": [
    "p0 = np.random.multivariate_normal(mean=result.x, cov=result.hess_inv, size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
